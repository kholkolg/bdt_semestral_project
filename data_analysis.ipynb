{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyspark --master yarn --num-executors 2 --executor-memory 4G --packages com.databricks:spark-csv_2.10:1.5.0 --conf spark.ui.port=10308\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import Row\t\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# daily weather averages\n",
    "df = sqlContext.sql('select * , date(to_date(datetime)) date from kholkolg.weather')\n",
    "avgs = df.groupBy(\"date\").agg({'temperature': 'mean', 'humidity': 'mean',\\\n",
    "                               'pressure': 'mean', 'wind_speed': 'mean'}).orderBy('date')\n",
    "\n",
    "avgs.write.format('com.databricks.spark.csv').save('user/kholkolg/nyc_results/weather_daily_means')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trips\n",
    "timeFmt = \"yyyy-MM-dd HH:mm:ss.SSSSSS\"\n",
    "kmPerMile = 1.609344 \n",
    "timeDiff = (F.unix_timestamp('dropoff_datetime', format=timeFmt)\n",
    "            - F.unix_timestamp('pickup_datetime', format=timeFmt))\n",
    "\n",
    "df = sqlContext.sql('''select count, pickup_datetime, dropoff_datetime, trip_distance from  kholkolg.nyc2015_trips ''')\n",
    "df = df.dropna()\n",
    "#raw data contains 146.112.989 entries \n",
    "\n",
    "#filter entries with dropoff time before pickup, zero length, or zero passengers\n",
    "df = df.filter(df.pickup_datetime <= df.dropoff_datetime)\n",
    "df = df.filter('count > 0')\n",
    "df = df.filter('trip_distance > 0')\n",
    "\n",
    "#compute trip duration in seconds\n",
    "df = df.withColumn('duration', timeDiff)\n",
    "#compute trip distance in meters, and speed in m/s\n",
    "df = df.withColumn('trip_distance', df['trip_distance']*kmPerMile*1000)\n",
    "df = df.withColumn('speed', df['trip_distance']/df['duration'])\n",
    "#remove bad speeds (40 m/s is smth around 130 km/h)\n",
    "df = df.filter('speed <= 40')\n",
    "#add day of year and  day of week\n",
    "df = df.withColumn('day_of_year', F.dayofyear('pickup_datetime'))\n",
    "df = df.withColumn('day_of_week', F.date_format('pickup_datetime', 'EEEE'))\n",
    "# add hour column\n",
    "df = df.withColumn(\"hour\", F.hour(F.unix_timestamp(\"pickup_datetime\").cast(\"timestamp\")))\n",
    "\n",
    "df.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# daily sums: passenger count, trip count, and total travelled distance\n",
    "sums = df.groupBy('day_of_year').agg(F.count('*').alias('trip_count'),\\\n",
    "                                     F.sum('count').alias('passenger_count'),\\\n",
    "                                     F.sum('trip_distance').alias('total_distance')).orderBy('day_of_year')\n",
    "sums.write.format('com.databricks.spark.csv').save('/user/kholkolg/nyc_results/trip_daily_sums')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trips by passenger count\n",
    "passengers = df.groupBy('day_of_year', 'count').agg(F.count('*').alias('trip_count')).orderBy('day_of_year')\n",
    "passengers.write.format('com.databricks.spark.csv').save('/user/kholkolg/nyc_results/daily_passengers')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trip counts, total duration, and average speed by weekday and daytime\n",
    "weekdayDF = df.groupBy('day_of_week', 'hour').agg(F.count('*').alias('trip_counts'),\\\n",
    "                                                  F.sum('duration').alias('total_duration'),\\\n",
    "                                                  F.avg('speed').alias('average_speed')).\\\n",
    "orderBy('day_of_week', 'hour')\n",
    "weekdayDF.write.format('com.databricks.spark.csv').save('/user/kholkolg/nyc_results/weekdays_stats')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Histograms\n",
    "num_bins = 50\n",
    "max_passenger = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distance \n",
    "distance_hist = df.select('trip_distance').rdd.flatMap(lambda x: x).histogram(num_bins)\n",
    "print(distance_hist)\n",
    "\n",
    "df3km = df.filter('trip_distance <= 3000')\n",
    "distance_hist3km = df3km.select('trip_distance').rdd.flatMap(lambda x:x).histogram(num_bins)\n",
    "print(distance_hist3km)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trip duration\n",
    "duration_hist = df.select('duration').rdd.flatMap(lambda x: x).histogram(num_bins)\n",
    "print(duration_hist)\n",
    "\n",
    "df30min = df.filter('duration <= 1800')\n",
    "duration_hist30min = df30min.select('duration').rdd.flatMap(lambda x: x).histogram(num_bins)\n",
    "print(duration_df30min)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average speed                                             \n",
    "speed_hist = df.select('speed').rdd.flatMap(lambda x: x).histogram(num_bins)\n",
    "print(speed_hist)\n",
    "#max speed around 40 km/h in m/s\n",
    "df40kmh = df.filter('speed <= 11.2')\n",
    "speed_40hist = df40kmh.select('speed').rdd.flatMap(lambda x: x).histogram(num_bins)\n",
    "print(speed_40hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# daily counts histograms \n",
    "daily_counts_hist = sums.select('trip_count').rdd.flatMap(lambda x: x).histogram(num_bins)\n",
    "print(daily_counts_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#copy results from local terminal\n",
    "scp -r kholkolg@hador.ics.muni.cz:~/nyc_results  /home/olga/Documents/BDT/results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
