{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### to copy files to/from local machine to metacentrum\n",
    "\n",
    "`scp -r path/to/data kholkolg@hador.ics.muni.cz:`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "### start hive\n",
    "\n",
    "`beeline -u \"jdbc:hive2://hador-c1.ics.muni.cz:10000/default;principal=hive/hador-c1.ics.muni.cz@ICS.MUNI.CZ\"`\n",
    "`use kholkolg;`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 1. External tables\n",
    "\n",
    "### 1.1 Trip data\n",
    "#### trip data.csv, 19 columns:\n",
    "*(VendorID, tpep_pickup_datetime, tpep_dropoff_datetime, passenger_count,*\n",
    "*trip_distance, pickup_longitude, pickup_latitude, RatecodeID,*\n",
    "*store_and_fwd_flag, dropoff_longitude, dropoff_latitude, payment_type,*\n",
    "*fare_amount, extra, mta_tax, tip_amount,*\n",
    "*tolls_amount, improvement_surcharge, total_amount)*\n",
    "\n",
    "\n",
    "drop table if exists nyc2015_ext;    \n",
    "\n",
    "create external table nyc2015_ext  \n",
    "(vendor int,  \n",
    " pickup_datetime timestamp,   \n",
    " dropoff_datetime timestamp,  \n",
    " count int,  \n",
    " trip_distance double,  \n",
    " pickup_longitude double,  \n",
    " pickup_latitude double,  \n",
    " rate int,  \n",
    " flag int, \n",
    " dropoff_longitude double,  \n",
    " dropoff_latitude double,  \n",
    " payment int,  \n",
    " fare_amount double,  \n",
    " extra double,  \n",
    " mta_tax double,  \n",
    " tip_amount double,  \n",
    " tolls_amount double,  \n",
    " improvement_surcharge double,  \n",
    " total_amount double )  \n",
    "row format delimited  \n",
    "fields terminated by ','  \n",
    "lines terminated by '\\n'  \n",
    "stored as textfile  \n",
    "location '/user/kholkolg/nyc2015'  \n",
    "tblproperties(\"skip.header.line.count\"=\"1\");    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "### 1.2 Weather\n",
    "drop table if exists weather_ext;   \n",
    "create external table weather_ext  \n",
    "(datetime timestamp,   \n",
    " temperature double,  \n",
    " humidity double,  \n",
    " pressure double,  \n",
    " wind_speed double,  \n",
    " description string)  \n",
    "stored as parquet  \n",
    "tblproperties(\"parquet.compress\"=\"SNAPPY\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "### 2. Select weather measurements for NY 2015\n",
    "\n",
    "\n",
    "`pyspark --master yarn --num-executors 2 --executor-memory 4G --packages com.databricks:spark-csv_2.10:1.5.0 --conf spark.ui.port=10308`\n",
    "\t\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import Row\t\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "from pyspark.sql import HiveContext\n",
    "\n",
    "dates = ('2015-01-01', '2016-01-01')\n",
    "#temperature\n",
    "temp = sqlContext.read.format(\"com.databricks.spark.csv\").\\\n",
    "                  option(\"header\", \"true\").option(\"inferSchema\", \"true\").\\\n",
    "                  load('/user/kholkolg/weather/temperature.csv')\n",
    "\n",
    "temp = temp.select('datetime', 'New York').where(F.col('datetime').between(*dates))\n",
    "temp = temp.withColumnRenamed('New York', 'temperature')\n",
    "temp = temp.withColumn('temperature', temp['temperature'] - 272.15) #convert to Celsius\n",
    "\n",
    "#humidity\n",
    "hum = sqlContext.read.format(\"com.databricks.spark.csv\").\\\n",
    "                  option(\"header\", \"true\").option(\"inferSchema\", \"true\").\\\n",
    "                  load('/user/kholkolg/weather/humidity.csv')\n",
    "hum = hum.select('datetime', 'New York').where(F.col('datetime').between(*dates))\n",
    "hum = hum.withColumnRenamed('New York', 'humidity')\n",
    "\n",
    "#pressure\n",
    "pressure = sqlContext.read.format(\"com.databricks.spark.csv\").\\\n",
    "                  option(\"header\", \"true\").option(\"inferSchema\", \"true\").\\\n",
    "                  load('/user/kholkolg/weather/pressure.csv')\n",
    "pressure = pressure.select('datetime', 'New York').where(F.col('datetime').between(*dates))\n",
    "pressure = pressure.withColumnRenamed('New York', 'pressure')\n",
    "\n",
    "#wind speed\n",
    "wind = sqlContext.read.format(\"com.databricks.spark.csv\").\\\n",
    "                  option(\"header\", \"true\").option(\"inferSchema\", \"true\").\\\n",
    "                  load('/user/kholkolg/weather/wind_speed.csv')\n",
    "wind = wind.select('datetime', 'New York').where(fun.col('datetime').between(*dates))\n",
    "wind = wind.withColumnRenamed('New York', 'wind_speed')\n",
    "\n",
    "#weather description\n",
    "weather = sqlContext.read.format(\"com.databricks.spark.csv\").\\\n",
    "                  option(\"header\", \"true\").option(\"inferSchema\", \"true\").\\\n",
    "                  load('/user/kholkolg/weather/weather_description.csv')\n",
    "weather = weather.select('datetime', 'New York').where(F.col('datetime').between(*dates))\n",
    "weather = weather.withColumnRenamed('New York', 'description')\n",
    "\n",
    "#join all dataframes and write to hive \n",
    "weather = temp.join(hum, 'datetime').join(pressure, 'datetime').join(wind, 'datetime').join(weather, 'datetime')\n",
    "weather2015.write.mode('overwrite').saveAsTable('kholkolg.weather_ext')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "### 2. Copy data to internal table\n",
    "set hive.exec.dynamic.partition=true;   \n",
    "set hive.exec.dynamic.partition.mode=nonstrict;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "### 2.2 Trips\n",
    "drop table if exists nyc2015_trips;\n",
    "\n",
    "create table nyc2015_trips  \n",
    "(pickup_datetime timestamp,  \n",
    " dropoff_datetime timestamp,  \n",
    " count int,  \n",
    " trip_distance double,   \n",
    " pickup_longitude double,   \n",
    " pickup_latitude double,  \n",
    " dropoff_longitude double,   \n",
    " dropoff_latitude double)  \n",
    "partitioned by (month int)  \n",
    "stored as orc  \n",
    "tblproperties(\"orc.compress\"=\"ZLIB\");  \n",
    "\n",
    "insert overwrite table nyc2015_trips  \n",
    "partition (month)  \n",
    "select pickup_datetime,  \n",
    "dropoff_datetime,  \n",
    "count,  \n",
    "trip_distance,  \n",
    "pickup_longitude,  \n",
    "pickup_latitude,   \n",
    "dropoff_longitude,  \n",
    "dropoff_latitude,\n",
    "month(to_date(pickup_datetime)) month  \n",
    "from nyc2015_ext;  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 2.2 Weather\n",
    "drop table if exists weather;\n",
    "\n",
    "create table weather  \n",
    "(datetime timestamp,  \n",
    " temperature double,  \n",
    " humidity double,  \n",
    " pressure double,  \n",
    " wind_speed double,  \n",
    " description string)  \n",
    "partitioned by (month int)  \n",
    "stored as orc  \n",
    "tblproperties(\"orc.compress\"=\"ZLIB\");  \n",
    "\n",
    "insert overwrite table weather  \n",
    "partition (month)  \n",
    "select datetime,  \n",
    "temperature,  \n",
    "humidity,  \n",
    "pressure,  \n",
    "wind_speed,  \n",
    "description,  \n",
    "month(to_date(datetime)) month  \n",
    "from weather_ext;  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
